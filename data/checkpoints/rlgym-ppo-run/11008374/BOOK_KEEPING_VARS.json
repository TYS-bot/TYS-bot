{
    "cumulative_timesteps": 11008374,
    "cumulative_model_updates": 392,
    "policy_average_reward": 157.81050923787205,
    "epoch": 99,
    "ts_since_last_save": 7200656,
    "reward_running_stats": {
        "mean": [
            0.27953510257197234
        ],
        "var": [
            1256839753.0828526
        ],
        "shape": [
            1
        ],
        "count": 15600
    },
    "wandb_run_id": "pnrrh8xn",
    "wandb_project": "rlgym-ppo",
    "wandb_entity": "",
    "wandb_group": "unnamed-runs",
    "wandb_config": {
        "n_proc": 45,
        "min_inference_size": 40,
        "timestep_limit": 100000000000,
        "exp_buffer_size": 150000,
        "ts_per_iteration": 300000,
        "standardize_returns": true,
        "standardize_obs": false,
        "policy_layer_sizes": [
            2048,
            1024,
            1024,
            1024
        ],
        "critic_layer_sizes": [
            2048,
            1024,
            1024,
            1024
        ],
        "ppo_epochs": 2,
        "ppo_batch_size": 50000,
        "ppo_minibatch_size": 25000,
        "ppo_ent_coef": 0.01,
        "ppo_clip_range": 0.1,
        "gae_lambda": 0.95,
        "gae_gamma": 0.99,
        "policy_lr": 2e-05,
        "critic_lr": 2e-05,
        "shm_buffer_size": 8192
    }
}